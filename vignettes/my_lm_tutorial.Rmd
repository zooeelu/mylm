---
title: "my_lm() tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my_lm() tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>", fig.width=6, fig.height=4)
options(tibble.print_min = 4L, tibble.print_max = 4L)
```

The my_lm() function was created to mimic the usage of the lm() function to run a basic linear regression model as a means of practicing writing packages in R. 

In this tutorial, we will go over the purpose of using the my_lm function I created as well as how to properly use it to ensure you get the results you want. We will also compare the accuracy and efficiency of my version of the lm function to R's official lm function in each example. This vignette will show you:

* How to use my_lm() to run a basic simple linear model.
* How to use my_lm() to run a multiple linear regression model with main effects, interaction effects etc.
* How to look at the output of the model to see the results of your linear model such as coefficient estimates, T and F values, p-values, etc.
* Comparisons between my_lm() and R's lm() function to show the accuracy and efficiency of my_lm() to the official lm() function

## Example 1
### Running the model using `my_lm()`

First lets load the package "mylm" which contains our my_lm() function:
```{r setup}
library(mylm)
```

In our first example, we'll use R's built in R dataset "iris" to run our desired model
```{r}
head(iris)
```

Suppose we are interested in studying the association between the Petal Width and the Sepal Length for the different species. Let's plot a basic scatterplot to get a better understanding of the type of association we might be looking for. 
```{r, out.width}
plot(iris$Sepal.Length, iris$Petal.Width,
     main = "Petal Width \n vs. Sepal Length",
     xlab = "Sepal Length", 
     ylab = "Petal Width")
```

Suppose now after seeing the scatterplot of Petal Width vs. Sepal Length you're interested in testing the association between the two variable to see if the association between the two is significant. We can then use the my_lm() function I created to test this association. 

The my_lm() function takes in two arguments: 

* `formula`: a linear regression formula
* `data`: a specified dataset that we want to run our model on

Lets now write and run our simple linear regression formula using `my_lm()` testing the association between the response variable "Petal Width" and our predictor variable "Sepal Length": 
```{r}
my_model <- my_lm(formula = Petal.Width ~ Sepal.Length, data = iris)
```

To see the results of our model, we can call multiple different outputs using $. 

For example, suppose we want to see the estimated coefficient values of our simple linear regression model as well as its corresponding standard error, t-values, and p-values. We can do this by running this line of code after our model has been run:

```{r}
my_model$Coefficients
```

Accessing "Coefficients" from running my_lm() will return a dataset consisting of all the coefficient values and the corresponding information 

If we just want to see the coefficient values we can extract the first column of the output of `my_model$Coefficients`. Similarly, we can do the same if we want to extract just the standard errors, t-values, etc.
```{r}
my_model$Coefficients[1]

my_model$Coefficients[2]

my_model$Coefficients[1:2]
```

Similarly, using the same logic as above, we can also look at the results of using my_lm() to run a linear model to access the F statistic of the model and its corresponding P-value. We can also look at the R-squared and adjusted R-squared

```{r}
my_model$fstatistic

my_model$F_statistic_P_Value

my_model$r.squared

my_model$adj.r.squared
```

Lastly, we can also access the model's fitted values and residual values if we ever decide to use them to do additional computational actions. We can follow similar steps as above to access these values. In this example, we will use the `head()` function to see the first 5 values of the fitted and residual values
```{r}
head(my_model$Fitted_Values, 5)

head(my_model$Residuals, 5)
```

### Comparing `my_lm()` with R's `lm()`
In this section of the example, we will compare our my_lm() function with R's lm() function to ensure that the values we obtained above are accurate and just as efficient as the original.

First let's run the same simple linear regression model but using R's lm() function:
```{r}
R_model <- lm(formula = Petal.Width ~ Sepal.Length, data = iris)
R_model_summary <- summary(R_model)
R_model_summary
```

To compare the accuracy and efficiency of our values and R's lm() values, we will use `all.equal` and `bench::mark` functions. Lets first compare the coefficient value table. We will make sure both coefficient tables are set as dataframes to ensure the right comparisons of values.
```{r}
R_model_coeffs <- data.frame(R_model_summary$coefficient)
my_model_coeffs <-  data.frame(my_model$Coefficients)

print(R_model_coeffs)
print(my_model_coeffs)

# accuracy
all.equal(R_model_coeffs, my_model_coeffs)

# efficiency
bench::mark(R_model_coeffs, my_model_coeffs)
```

We can see that the `all.equal` function returns `TRUE` indicating that when it comes to looking at the coefficient table, our my_lm() function matches R's lm() function indicating that our function is running correctly. Additionally, we can see that our my_lm() function is also quite efficient and is even more efficient than R's lm() function for regular sized datasets.

Similarly, lets also double check the R-squared, Adjusted R-squared, F Statistic, F Statistic p-value, fitted values, and residuals using the same method as above:
```{r}
# checking R-squared
R_model_summary$r.squared
my_model$adj.r.squared

# accuracy
all.equal(R_model_summary$r.squared, my_model$r.squared)

# efficiency
bench::mark(R_model_summary$r.squared, my_model$r.squared)
```

```{r}
# checking the Adjusted R-squared
R_model_summary$adj.r.squared
my_model$adj.r.squared

# accuracy
all.equal(R_model_summary$adj.r.squared, my_model$adj.r.squared)

# efficiency
bench::mark(R_model_summary$adj.r.squared, my_model$adj.r.squared)
```

```{r}
# checking F statistic 
R_model_summary$fstatistic[[1]]
my_model$fstatistic

lm_f_p_value <- R_model_summary$fstatistic[[1]]  # F-statistic value
lm_f_p_value <- pf(lm_f_p_value, df1 = R_model_summary$fstatistic[[2]], 
                     df2 = R_model_summary$fstatistic[[3]], lower.tail = FALSE)
lm_f_p_value
my_model$F_statistic_P_Value

# accuracy
all.equal(lm_f_p_value, my_model$F_statistic_P_Value)

# efficiency
bench::mark(lm_f_p_value, my_model$F_statistic_P_Value)
```


```{r}
# checking fitted values
R_fitted <- as.vector(R_model$fitted.values)
my_fitted <- as.vector(my_model$Fitted_Values)
head(R_fitted)
head(my_fitted)

# accuracy
all.equal(R_fitted, my_fitted)

# efficiency
bench::mark(R_fitted, my_fitted)
```

```{r}
# checking residuals
R_res<- as.vector(R_model_summary$residuals)
my_res <- as.vector(my_model$Residuals)
head(R_res)
head(my_res)

# accuracy
all.equal(R_res, my_res)

# efficiency
bench::mark(R_res, my_res)
```

**From above, we can see that all the possible values from our my_lm() function matches R's lm() function. This shows that our my_lm() function is well constructed and produces accurate results. We can also see that all of our outputs using the my_lm() function has similar efficiency with not many big differences compared to R's lm() function for regular datasets. Our my_lm() function is accurate and is not inefficient.**
